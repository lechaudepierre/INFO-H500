{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2548ef4",
   "metadata": {},
   "source": [
    "## Introduction to DICOM, NIfTI and basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f522d",
   "metadata": {},
   "source": [
    "In this notebook, we will explore two common medical imaging file formats: **DICOM (Digital Imaging and Communications in Medicine)** and **NIfTI (Neuroimaging Informatics Technology Initiative)**. These formats are widely used in clinical and research environments respectively, each with its own strengths and use cases.\n",
    "\n",
    "The main objectives of this module are:\n",
    "- Understanding DICOM Files\n",
    "-  Understanding NIfTI Files\n",
    "- Basic Image Visualization (DICOM & NIfTI)\n",
    "- Basic Preprocessing and Image Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac4859",
   "metadata": {},
   "source": [
    "### 1. Introduction to DICOM Files\n",
    "\n",
    "#### What is a DICOM File?\n",
    "[DICOM](https://www.dicomstandard.org/) (Digital Imaging and COmmunications in Medicine) is the de-facto standard that establishes rules that allow medical images (X-Ray, MRI, CT) and associated information to be exchanged between imaging equipment from different vendors, computers, and hospitals. It not only stores the image but also includes important metadata such as patient details, modality (e.g., CT, MRI), image orientation, pixel spacing, and much more. The DICOM format provides a suitable means that meets health information exchange (HIE) standards for transmission of health related data among facilities and HL7 standards which is the messaging standard that enables clinical applications to exchange data.\n",
    "\n",
    "DICOM files typically have a .dcm extension and provides a means of storing data in separate ‘tags’ such as patient information, image/pixel data, the machine used, etc.\n",
    "\n",
    "For more information, refer to : https://www.dicomstandard.org/about-home\n",
    "\n",
    "#### Use Cases:\n",
    "- **DICOM** is heavily used in hospitals and clinics because it integrates with medical imaging equipment.\n",
    "- **Clinical Metadata**: DICOM files include vital information about the patient and imaging modality, which is essential for diagnosis and treatment.\n",
    "\n",
    "#### Structure of a DICOM File\n",
    "A typical DICOM file contains:\n",
    "- **Header**: Contains metadata such as patient ID, modality, and image acquisition details.\n",
    "- **Image Data**: The pixel data representing the actual image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fa77e",
   "metadata": {},
   "source": [
    "#### Load and read a DICOM image\n",
    "\n",
    "\n",
    "The following package supports working with DICOM files:\n",
    "\n",
    "- [pydicom](https://pydicom.github.io/) is a dedicated library for handling DICOM files, allowing access to both pixel data and the associated metadata (e.g., patient details, equipment information, scan parameters). pydicom is ideal when working in medical contexts where you need to inspect, modify, or extract specific information from the DICOM headers in addition to the image data. `pydicom` is best for comprehensive access to both image and metadata, useful when medical details are required for further analysis. It provides pixel data as a NumPy array via the pixel_array attribute, which can be processed and visualized easily. `pydicom` is commonly used with `numpy` and `matplotlib`. `numpy` provides a flexible and efficient structure (the NumPy array) to store and manipulate image data across all three libraries (imageio, pydicom, and scipy.ndimage) and `matplotlib.pyplot` is used to visualize the image data after it's loaded and processed, displaying it in an intuitive and customizable way.\n",
    "\n",
    "\n",
    "When working with DICOM files, they may sometimes be compressed into a .zip archive. To handle this, we first need to unzip the files before reading them. This can be done easily using Python's `zipfile` module to unzip the DICOM file, or you can unzip the file using the GUI.\n",
    "\n",
    "To read the image, using the `pydicom` library use the `dcmread()` function, which gives you access to the pixel data via the pixel_array attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "# Path to the zip file and the directory where the contents will be extracted\n",
    "#zip_file_path = '/path/to/your/dicom_files.zip'\n",
    "#extract_dir = '/path/to/extract/'\n",
    "zip_file_path = '/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/DICOM.zip'\n",
    "extract_dir = '/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/'\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(zip_file_path):\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extracted files to {extract_dir}\")\n",
    "    \n",
    "    # List the contents of the extracted folder\n",
    "    extracted_files = os.listdir(extract_dir)\n",
    "    print(\"Extracted DICOM files:\")\n",
    "    for file in extracted_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(f\"Zip file not found: {zip_file_path}\")\n",
    "\n",
    "# Directory containing your DICOM files\n",
    "dicom_dir = '/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/DICOM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34f036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required libraries\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a99aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DICOM file\n",
    "dicom_file_path = os.path.join(extract_dir, 'DICOM/IM-0004-0096.dcm')\n",
    "dicom_data = pydicom.dcmread(dicom_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09c256",
   "metadata": {},
   "source": [
    "#### Read Metadata\n",
    "\n",
    "Metadata refers to supplementary information that describes or provides context for the primary data, such as images or documents. In the context of medical imaging, metadata includes details about how, when, and with what equipment an image was acquired. This might involve information such as the date of the scan, scanner settings, patient demographics (excluding personally identifiable information if anonymized), and details about the imaging modality.\n",
    "Since this scan was acquired for research purposes, the \"patient\" information does not contain personally-identifying information like the name or birth. date of the person who was scanned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dicom_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb3297",
   "metadata": {},
   "source": [
    "In DICOM files, metadata is organized into various elements. These elements store both the image data and essential metadata. \n",
    "The print output shows a list of the data elements (or elements for short) present in the dataset, one element per line. The format of each line is:\n",
    "\n",
    "- `(0008, 0005)`: The element’s tag, as (group number, element number) in hexadecimal\n",
    "\n",
    "- `Specific Character Set`: the element’s name, if known\n",
    "\n",
    "- `CS`: The element’s Value Representation (VR), if known\n",
    "\n",
    "- `‘ISO_IR_100’`: the element’s stored value\n",
    "\n",
    "There are three main categories of DICOM elements:\n",
    "\n",
    "- **Standard Elements**: Defined in the DICOM standard, have even group numbers, and store common metadata.\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        `(0008,0016)` - SOP Class UID\n",
    "        `(0008,0020)` - Study Date\n",
    "- **Repeating Group Elements**: Allow multiple occurrences at the same level, with group numbers in a range.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        `(60xx,3000)` - Overlay Data (where xx can be 0x6000, 0x6002, 0x6004, etc., up to 0x601E).\n",
    "\n",
    "- **Private Elements**: Created by manufacturers, have odd group numbers, and can store vendor-specific data. \n",
    "\n",
    "    Example:\n",
    "\n",
    "         `(0043,104E)` - [Duration of X-ray on] (Private Element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5467d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "This structure allows DICOM to be highly extensible, accommodating both standardized and vendor-specific data. You can explore these elements using pydicom to retrieve both standard and custom metadata from medical images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca42bb",
   "metadata": {},
   "source": [
    "In pydicom, you can access all of these elements and their values directly from the DICOM object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a670e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print metadata\n",
    "print(\"Patient ID:\", dicom_data.PatientID)\n",
    "print(\"Modality:\", dicom_data.Modality)\n",
    "print(\"Image Dimensions:\", dicom_data.Rows, \"x\", dicom_data.Columns)\n",
    "print(\"Pixel Spacing:\", dicom_data.PixelSpacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373d02b",
   "metadata": {},
   "source": [
    "The `pydicom` library allows you to access the image's pixel data stored in the DICOM file using the pixel_array attribute. This data represents the raw pixel intensity values of the medical image, which can be visualized using libraries like matplotlib.\n",
    "\n",
    "In the following code, we use pydicom to read the DICOM file and extract the pixel data. We then use matplotlib to display the image in grayscale, which is common for medical images such as X-rays, CT scans, and MRIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4032a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pixel data\n",
    "dicom_image = dicom_data.pixel_array\n",
    "\n",
    "# Print the dimensions of the DICOM image\n",
    "print(\"DICOM Image Dimensions:\", dicom_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3faf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DICOM image as a NumPy array\n",
    "print(\"DICOM Image as a NumPy Array:\")\n",
    "print(dicom_image)\n",
    "\n",
    "# You can also print some statistics for better readability\n",
    "print(\"Min pixel value of the first slice:\", np.min(dicom_image))\n",
    "print(\"Max pixel value of the first slice:\", np.max(dicom_image))\n",
    "print(\"Mean pixel value of the first slice:\", np.mean(dicom_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the DICOM image\n",
    "plt.imshow(dicom_image, cmap='gray')\n",
    "plt.title('DICOM Image')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61bb293",
   "metadata": {},
   "source": [
    "The metadata and pixel information has been extracted here for a single .dcm file. We can also index the multiple .dcm files we extracted and perform the same functions as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all DICOM files in the directory\n",
    "dicom_files = [os.path.join(dicom_dir, f) for f in os.listdir(dicom_dir) if f.endswith('.dcm')]\n",
    "\n",
    "# Sort files by instance number or another DICOM attribute if required\n",
    "dicom_files.sort(key=lambda x: pydicom.dcmread(x).InstanceNumber)\n",
    "\n",
    "# Initialize a list to store all slices\n",
    "brain_slices = []\n",
    "\n",
    "# Read each DICOM file and store the pixel data in the brain_slices list\n",
    "for dicom_file in dicom_files:\n",
    "    dicom_data = pydicom.dcmread(dicom_file)\n",
    "    brain_slices.append(dicom_data.pixel_array)\n",
    "\n",
    "# Convert to a NumPy array for easier manipulation (optional)\n",
    "brain_slices = np.array(brain_slices)\n",
    "\n",
    "# Now you can access each slice like brain_slice[0], brain_slice[1], etc.\n",
    "\n",
    "# Print the shape (dimensions) of the brain_slices array\n",
    "print(\"DICOM Image Stack Dimensions (slices, height, width):\", brain_slices.shape)\n",
    "\n",
    "# Print the pixel array of the first slice (brain_slice[0])\n",
    "print(\"Pixel data of the first slice (brain_slice[0]):\")\n",
    "print(brain_slices[0])\n",
    "\n",
    "# You can also print some statistics for better readability\n",
    "print(\"Min pixel value of the first slice:\", np.min(brain_slices[0]))\n",
    "print(\"Max pixel value of the first slice:\", np.max(brain_slices[0]))\n",
    "print(\"Mean pixel value of the first slice:\", np.mean(brain_slices[0]))\n",
    "\n",
    "# Visualize the DICOM image\n",
    "plt.imshow(brain_slices[0], cmap='gray')\n",
    "plt.title('DICOM Image')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4a655",
   "metadata": {},
   "source": [
    "Unlike the 0-255 pixel intensity range in standard images, MRI scans in DICOM format store pixel values that represent signal intensities. MRI images capture different contrasts based on tissue properties (e.g., T1-weighted, T2-weighted, etc.), and these signal intensities can vary widely depending on the type of sequence and scan parameters. Pixel values can range from 0 to very high values (7000-9000 as above), depending on the scanning modality, resolution, and what part of the body is being imaged.\n",
    "\n",
    "```\n",
    "[[ 0  0  0 ...  8  5  2]\n",
    " [ 0  0  0 ...  6  0  5]\n",
    " [ 0  0  0 ... 17 24  5]\n",
    " ...\n",
    " [ 0  0  0 ...  0  0  0]\n",
    " [ 0  0  0 ...  0  0  0]\n",
    " [ 0  0  0 ...  0  0  0]]\n",
    "```\n",
    "This array represents the raw pixel intensity values of the DICOM slice, where:\n",
    "\n",
    "- 0 typically represents the background or areas outside the brain, where no signal is detected.\n",
    "- Higher values represent areas with higher signal intensity, which may correlate with different tissue types or abnormalities (depending on the MRI modality).\n",
    "\n",
    "The output pixel statistics for slice [0] represents:\n",
    "\n",
    "- Min pixel value (0): This is common for regions outside the tissue, like air or background.\n",
    "- Max pixel value (7017): This could correspond to areas of high signal intensity, such as regions with strong MRI signals like blood vessels or contrast-enhanced regions.\n",
    "- Mean pixel value (1246.57): This gives you an idea of the overall signal intensity of the slice, indicating the average brightness across the slice.\n",
    "\n",
    "The reason for such values, in comaprison to the traditional 0-255 range we deal with for standard image formats (JPEG, PNG, etc.) is because these formats use 8-bit per channel color depth. These values represent the intensity of each pixel for grayscale images or the intensity of each color channel (red, green, blue) in color images.\n",
    "\n",
    "In medical images, particularly in formats like DICOM or NIfTI, pixel values represent more than just simple intensity. They often carry information about the tissue characteristics, physical properties (like density or radiodensity), or signal intensities from imaging machines like CT or MRI. These values are stored in floating-point or higher-bit integers to capture a wider dynamic range of intensities, which is essential for accurate diagnosis. \n",
    "\n",
    "MRI scanners store signal intensities using 12-bit or 16-bit depth, which means that pixel values can exceed the 255 range of standard images, allowing for much higher precision in intensity values. In this case, the maximum pixel value of 7017 is quite typical for high-resolution medical images, particularly in MRI.\n",
    "The full range of pixel values might not always be directly useful for visualization. In clinical practice, radiologists use windowing techniques to adjust the display of these pixel values to fit the display range (e.g., 0-255), highlighting specific tissues of interest. However, for data analysis, usually we work with the raw pixel values (like in an array), which preserve the full dynamic range of the MRI scan. \n",
    "\n",
    "The non-normalized image displayed perfectly suggests that the DICOM image already contains pixel values in an appropriate range for visualization. Commonly, DICOM files include fields like `RescaleSlope` and `RescaleIntercept`, which transform raw pixel values into a more meaningful range (e.g., Hounsfield units for CT scans). MRI scans often have pixel intensities that map to tissue types or structures in the body, so forcing them into a 0-255 range can remove useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c173108",
   "metadata": {},
   "source": [
    "#### Visualize a slice through different planes\n",
    "\n",
    "Since the data are a 3D NumPy array, it is very easy to \"reslice\" the image and visualize the head from one of the other two orientations, axial and coronal. Below we pass `:` to select all sagittal slices, and `128` for the second dimension to get the slice midway through the volume, in the axial plane. Again, we omit the third dimension and so `:` is assumed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba514405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load DICOM volume\n",
    "def load_dicom_volume(dicom_dir):\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(dicom_dir)):\n",
    "        if filename.endswith('.dcm'):\n",
    "            ds = pydicom.dcmread(os.path.join(dicom_dir, filename))\n",
    "            slices.append(ds.pixel_array)\n",
    "    \n",
    "    # Stack slices into a 3D volume\n",
    "    volume = np.stack(slices, axis=-1)\n",
    "    return volume\n",
    "\n",
    "# Load the volume\n",
    "brain_vol_dicom = load_dicom_volume(dicom_dir)\n",
    "\n",
    "# Ensure the volume has the expected dimensions\n",
    "assert len(brain_vol_dicom.shape) == 3, \"Expected 3D volume. Please check your DICOM files.\"\n",
    "\n",
    "# Determine middle slices for each plane\n",
    "z_middle = brain_vol_dicom.shape[2] // 2\n",
    "y_middle = brain_vol_dicom.shape[1] // 2\n",
    "x_middle = brain_vol_dicom.shape[0] // 2\n",
    "\n",
    "# Plotting Saggital Plane (Z-axis slices)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(brain_vol_dicom[:, :, z_middle], cmap='bone')\n",
    "plt.title('Saggital Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Coronal Plane (Y-axis slices)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(brain_vol_dicom[:, y_middle, :], cmap='bone')\n",
    "plt.title('Coronal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Axial Plane (X-axis slices)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(brain_vol_dicom[x_middle, :, :], cmap='bone')\n",
    "plt.title('Axial Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4f758",
   "metadata": {},
   "source": [
    "#### Plotting an image histogram\n",
    "\n",
    "As we saw above, the image is stored as a NumPy array, in which each voxel in the image is represented as a number, which is mapped to an intensity value in the colourmap when plotting. Larger values appear as brighter (whiter), and lower values appear as darker.\n",
    "\n",
    "Histograms of the anatomical images show the number of voxels of a given intensity value. These can be informative because the distribution of intensity values in an anatomical image is not uniform. Instead, as we can see above, there are many very dark voxels (outside of the head, and in some of the fluid-filled spaces inside the head), and then clusters of voxels that are darker grey (the grey matter, largely in the cerebral cortex that forms the outer layer of the brain), lighter grey (the white matter that comprises much of the inside of the brain), and also some very bright areas that are primarily due to areas of fat concentration.\n",
    "\n",
    "We can use ndimage's `.histogram()` function to plot a histogram of our brain volume. We use this rather than the NumPy `histogram` function, because ndimage's function is designed to work with 3D images. This function requires several arguments, including the minimum and maximum intensity values that define the range of the *x* axis of the histogram, and the number of bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the image data to 1D for the histogram\n",
    "brain_vol_data_flat_dicom = brain_vol_dicom.flatten()\n",
    "\n",
    "# Plot the histogram\n",
    "\n",
    "plt.plot(ndi.histogram(brain_vol_dicom, min=0, max=np.max(brain_vol_dicom), bins=50))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(brain_vol_data_flat_dicom, bins=100, color='c', edgecolor='k')\n",
    "plt.title('Histogram of Brain NIfTI Image Data')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the image data to 1D for the histogram\n",
    "brain_vol_data_flat_dicom = brain_vol_dicom.flatten()\n",
    "\n",
    "# Plot the histogram\n",
    "\n",
    "plt.plot(ndi.histogram(brain_vol_dicom, min=0, max=np.max(brain_vol_dicom), bins=50))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(brain_vol_data_flat_dicom, bins=100, color='c', edgecolor='k')\n",
    "plt.title('Histogram of Brain NIfTI Image Data')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e0753",
   "metadata": {},
   "source": [
    "In the histogram above, there is a large peak close to zero which represents the fact that a large number of voxels in the image don't contain the head at all, and therefore have values at or close to zero. We can see a peak just above 10 on the *x* axis (note that the numbers on the *x* axis are bin numbers, not intensity values), with a slight decrease and then a second small peak just before 20, followed by a flat area. The peaks just above 10 and just below 20 reflect the concentration of similar intensity values corresponding to grey and white matter respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173a396",
   "metadata": {},
   "source": [
    "### 2. Introduction to NIfTI Files\n",
    "\n",
    "#### What is a NIfTI File?\n",
    "[NIfTI](https://nifti.nimh.nih.gov/) (Neuroimaging Informatics Technology Initiative) is a file format initially designed for neuroimaging data, such as fMRI and MRI. While it remains highly popular in neuroimaging, NIfTI is now also used in various other fields that involve volumetric medical imaging, such as cancer research and anatomical imaging.\n",
    "\n",
    "NIfTI was created to standardize image storage across different software tools. It provides a structured way to store 3D or 4D imaging data and includes crucial metadata for accurate image orientation, which helps avoid potential errors during analysis. NIfTI files are typically stored with a .nii extension and can be compressed using Gzip to save storage space.\n",
    "\n",
    "\n",
    "#### Use Cases\n",
    "- **NIfTI** is predominantly used in research settings, especially in neuroimaging studies.\n",
    "- **Efficient Storage**: NIfTI focuses on image data ather than clinical metadata, making it a more compact format for storing 3D or 4D volumes.\n",
    "\n",
    "#### Structure of a NIfTI File\n",
    "A typical NIfTI file contains:\n",
    "- **Header**: Includes metadata such as image dimensions, voxel sizes, and orientation.\n",
    "- **Image Data**: The actual voxel data representing the 3D or 4D image.\n",
    "\n",
    "#### Loading and Visualizing NIfTI Files\n",
    "To work with NIfTI files, we use specific libraries designed for handling this format:\n",
    "\n",
    "- `nibabel`: A library dedicated to reading and writing NIfTI files. It allows access to both image data and header information, making it possible to inspect and modify metadata, as well as manipulate image data.\n",
    "- `nilearn`: A library built on top of nibabel that provides additional tools for statistical analysis and visualization of neuroimaging data. It simplifies tasks such as brain image visualization and analysis, making it ideal for research workflows.\n",
    "\n",
    "\n",
    "Just as for pydicom, these libraries use `numpy` and `matplotlib` for  handling and manipulating image data loaded from NIfTI files and for creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552d99e",
   "metadata": {},
   "source": [
    "#### Loading and Visualizing DICOM Files\n",
    "\n",
    "Let’s start by loading a DICOM file and inspecting its metadata. For this lab we will work with structural MRI images of a brain, visualize them as slices, and perform a couple of simple image processing operations on images.\n",
    "\n",
    "Structural MRI is a generic term for any MRI scan intended to image the structure of the body. These are sometimes called anatomical scans. This is in contrast to functional MRI, which are scans designed to measure some aspect of physiological function (typically neural activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dc25a97-910e-42c5-a962-892cabba37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required libraries\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bac565-fa1d-4467-a1da-947fd9a37b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a NiFTI file\n",
    "brain_vol_nii = nib.load('/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/brain1.nii')\n",
    "\n",
    "# What is the type of this object?\n",
    "type(brain_vol_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5ebef-feee-44fd-b2a2-dd1ccd55f4e2",
   "metadata": {},
   "source": [
    "#### View metadata\n",
    "\n",
    "We can view the image's header by printing it (note that due to how the NiBabel `Nifti1Image` object is coded, we need to `print()` the header rather than just asking for it as a property):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc91a3e-aa9f-49d0-bbd6-bd66614a89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print metadata\n",
    "print(brain_vol_nii.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f82d91-ca0a-48fd-82d1-b162ad0bfee5",
   "metadata": {},
   "source": [
    "#### Access data in the NIfTI object\n",
    "\n",
    "NiBabel's handling of the NIfTI format data is not quite as elegant. Rather than being able to access the data directly by referencing the name of the object (in this case, `brain_vol`), we need to use the method `get_fdata()` to do this (the \"f\" in this method name stands for \"floating point\", as this is the type of data it returns). We will assign the result of this to a new variable so that it's easy to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26e91e-75e5-44a0-8e69-99112ed7d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pixel data\n",
    "brain_vol_nii = brain_vol_nii.get_fdata()\n",
    "type(brain_vol_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f48fa5-7d8c-42d5-aaf1-79f1ab6bc626",
   "metadata": {},
   "source": [
    "We see that the data is a familiar NumPy array, and below we see the dimensions are identical to what we saw for this image in the previous lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72dc94-f45e-423d-9028-5066a93aceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dimensions of the DICOM image\n",
    "brain_vol_nii.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1174a1c-fc2f-4df0-903d-6e6e8b411553",
   "metadata": {},
   "source": [
    "#### Visualize a slice\n",
    "\n",
    "We can use `.plt.imshow()` as in the previous lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4090ff3-cf95-4b1a-b612-7a69a18ee978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the middle slice\n",
    "slice_index = brain_vol_nii.shape[2] // 2\n",
    "slice_data = brain_vol_nii[:, :, slice_index]\n",
    "\n",
    "# Display the slice\n",
    "plt.imshow(slice_data, cmap='gray', aspect='auto')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5bc0e-7088-4784-ae56-620a08e6d048",
   "metadata": {},
   "source": [
    "Note that our image is rotated, so use can use `ndi.rotate` to fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aab96d-38fa-4fc1-83c3-ddfb77fb6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndi.rotate(brain_vol_nii[50], 50), cmap='bone')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4df76-2df7-4d75-9cb6-e96c1b20bf44",
   "metadata": {},
   "source": [
    "#### Plot a series of slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58cc45-4645-4742-a056-9a3322977d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rows = 4\n",
    "fig_cols = 4\n",
    "n_subplots = fig_rows * fig_cols\n",
    "n_slice = brain_vol_nii.shape[0]\n",
    "step_size = n_slice // n_subplots\n",
    "plot_range = n_subplots * step_size\n",
    "start_stop = int((n_slice - plot_range) / 2)\n",
    "\n",
    "fig, axs = plt.subplots(fig_rows, fig_cols, figsize=[10, 10])\n",
    "\n",
    "for idx, img in enumerate(range(start_stop, plot_range, step_size)):\n",
    "    axs.flat[idx].imshow(ndi.rotate(brain_vol_nii[img, :, :], 90), cmap='gray')\n",
    "    axs.flat[idx].axis('off')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b003f3",
   "metadata": {},
   "source": [
    "#### Calculate the pixel statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(range(start_stop, plot_range, step_size)):\n",
    "    slice_data = brain_vol_nii[img, :, :]\n",
    "    \n",
    "    # Handle negative values if they are unexpected\n",
    "    # Option 1: Use absolute values\n",
    "    # slice_data = np.abs(slice_data)\n",
    "    \n",
    "    # Option 2: Report if negative values are present\n",
    "    if np.any(slice_data < 0):\n",
    "        print(f\"Warning: Negative pixel values found in slice {img}\")\n",
    "    \n",
    "    # Compute statistics for the current slice\n",
    "    min_val = np.min(slice_data)\n",
    "    max_val = np.max(slice_data)\n",
    "    mean_val = np.mean(slice_data)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Slice Index: {img}\")\n",
    "    print(f\"Min pixel value: {min_val:.2f}\")\n",
    "    print(f\"Max pixel value: {max_val:.2f}\")\n",
    "    print(f\"Mean pixel value: {mean_val:.2f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711a285",
   "metadata": {},
   "source": [
    "Negative pixel values in the NIfTI images are be related to the high range of pixel intensities observed in the MRI data. From the header of this NiFTI:\n",
    "\n",
    "- The use of `float32` format, which supports negative values.\n",
    "- Missing scaling information (`scl_slope` and `scl_inter`), leaving pixel values in their raw form.\n",
    "- Possible baseline or mean adjustments applied to the image data during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the volume has the expected dimensions\n",
    "assert len(brain_vol_nii.shape) == 3, \"Expected 3D volume. Please check your NIfTI file.\"\n",
    "\n",
    "# Determine middle slices for each plane\n",
    "z_middle = brain_vol_nii.shape[2] // 2\n",
    "y_middle = brain_vol_nii.shape[1] // 2\n",
    "x_middle = brain_vol_nii.shape[0] // 2\n",
    "\n",
    "# Plotting Axial Plane (Z-axis slices)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(brain_vol_nii[:, :, z_middle], cmap='bone')\n",
    "plt.title('Axial Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Coronal Plane (Y-axis slices)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(brain_vol_nii[:, y_middle, :], cmap='bone')\n",
    "plt.title('Coronal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Sagittal Plane (X-axis slices)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(brain_vol_nii[x_middle, :, :], cmap='bone')\n",
    "plt.title('Sagittal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Rotated Axial Plane\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(ndi.rotate(brain_vol_nii[:, :, z_middle], 270), cmap='bone')\n",
    "plt.title('Rotated Axial Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Rotated Coronal Plane\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(ndi.rotate(brain_vol_nii[:, y_middle, :], 270), cmap='bone')\n",
    "plt.title('Rotated Coronal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Rotated Sagittal Plane\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(ndi.rotate(brain_vol_nii[x_middle, :, :], 270), cmap='bone')\n",
    "plt.title('Rotated Sagittal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f014ef",
   "metadata": {},
   "source": [
    "\n",
    "The issue with the rotations of the coronal and sagittal planes for NIfTI images likely arises because the axes in the NIfTI format may be oriented differently than expected. To ensure correct orientation for the coronal and sagittal planes, it’s important to carefully adjust the rotation and perhaps transpose the axes before applying the rotate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b98c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Coronal Plane (Y-axis slices) - Adjusted with Transpose\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.transpose(brain_vol_nii[:, y_middle, :]), cmap='bone')\n",
    "plt.title('Coronal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting the Sagittal Plane (X-axis slices) - Adjusted with Transpose\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.transpose(brain_vol_nii[x_middle, :, :]), cmap='bone')\n",
    "plt.title('Sagittal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now, let's rotate each plane correctly\n",
    "# Plotting Rotated Axial Plane (no change in orientation)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(ndi.rotate(brain_vol_nii[:, :, z_middle], 270), cmap='bone')\n",
    "plt.title('Rotated Axial Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Rotated Coronal Plane (correct transpose and then rotate)\n",
    "plt.subplot(1, 3, 2)\n",
    "rotated_coronal = np.transpose(brain_vol_nii[:, y_middle, :])\n",
    "plt.imshow(ndi.rotate(rotated_coronal, 90), cmap='bone')\n",
    "plt.title('Rotated Coronal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plotting Rotated Sagittal Plane (correct transpose and then rotate)\n",
    "plt.subplot(1, 3, 3)\n",
    "rotated_sagittal = np.transpose(brain_vol_nii[x_middle, :, :])\n",
    "plt.imshow(ndi.rotate(rotated_sagittal, 90), cmap='bone')\n",
    "plt.title('Rotated Sagittal Plane')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be54919-b388-45fd-9352-3b149aea9039",
   "metadata": {},
   "source": [
    "#### Plot with NiLearn\n",
    "\n",
    "While SciPy's ndimage module was designed for working with a wide variety of image types, NiLearn was designed to work with neuroimaging data specifically. As such, it's tools are a bit easier to use and more purpose-built for tasks that neuroimaging data scientists might want to perform. For example, we can plot the NiBabel NIfTI image object directly without first having to extract the data, using the `plot_img()` function from NiLearn's `plotting` module:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c83f71-891e-4764-bdc2-00044731873d",
   "metadata": {},
   "source": [
    "One nice thing that we see is that since NiLearn is neuroimaging-aware, it explicitly adds labels to our plot showing us clearly which the left and right hemispheres are.\n",
    "\n",
    "NiLearn's plotting library uses Matplotlib, so we can use familiar tricks to do things like adjust the image size and colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a04de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_vol_nii = nib.load('/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/brain1.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4c387-27ae-48a8-95af-eccf449b1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10, 5])\n",
    "plotting.plot_img(brain_vol_nii, cmap='gray', axes=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ca9bf-da00-4bcc-bf87-740e8b32e682",
   "metadata": {},
   "source": [
    "The `plot_img()` function also provides a variety of ways to display the brain, with much less code than we had to use when working with raw NumPy arrays and Matplotlib functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fc207-0623-430b-a417-8c4ca9742f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(brain_vol_nii, display_mode='tiled', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446ac35-77ec-40c8-82b3-b67a3d045e64",
   "metadata": {},
   "source": [
    "We can use the `cut_coords` kwarg to specify there to centre the crosshairs and \"cuts\" through the image that we visualize. In this image, the coordinates are relative to the *isocenter of the MRI scanner — the centre of the magnetic field inside the scanner. The position of a person's head relative to this isocenter will vary from individual to individual, and scan to scan, due to variations in head size and the optimizations used by the MRI technician and scanner. But we can use the coordinates printed in the above image (which defaulted to the centre of the image volume) and some trial-and-error to get a different view through the brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34702bb-8d13-45ce-9124-ec62292f1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(brain_vol_nii, cmap='gray', cut_coords=(-45, 40, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc9066-a531-4318-90f5-4944d3dafbf1",
   "metadata": {},
   "source": [
    "`plot_img()` also has a few other ways to see multiple slices at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd7187-628d-4dc7-a4c2-b6b9987d1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(brain_vol_nii, display_mode='x', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2081e6f-cde5-48b6-a9ac-e743356fb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(brain_vol_nii, display_mode='mosaic', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197c6af",
   "metadata": {},
   "source": [
    "#### Plotting the image histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the image data from the NIfTI file\n",
    "brain_vol_data = brain_vol_nii.get_fdata()\n",
    "\n",
    "# Create a histogram using numpy for the NIfTI data\n",
    "hist_values, bin_edges = np.histogram(brain_vol_data, bins=50, range=(0, np.max(brain_vol_data)))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.plot(bin_edges[:-1], hist_values)  # bin_edges has one more element than hist_values\n",
    "plt.title('Histogram of Brain NIfTI Image Data')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Flatten the image data to 1D for the histogram\n",
    "brain_vol_data_flat = brain_vol_nii.get_fdata().flatten()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(brain_vol_data_flat, bins=100, color='c', edgecolor='k')\n",
    "plt.title('Histogram of Brain NIfTI Image Data')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6a0b8",
   "metadata": {},
   "source": [
    "### Basic Preprocessing and Image Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07936bf6",
   "metadata": {},
   "source": [
    "There are several image quality measurements that are commonly used in medical image analysis to assess the quality of an image, These include metrics that evaluate noise, contrast, sharpness, and overall fidelity of the image. Some key image quality metrics that can be included are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685aa627",
   "metadata": {},
   "source": [
    "1. **Signal-to-Noise Ratio (SNR)**: SNR measures the amount of signal present in an image compared to the noise. Higher SNR values indicate clearer images with less noise. The SNR can be calculated by dividing the mean pixel intensity of the signal by the standard deviation of the background (noise).\n",
    "2. **Contrast-to-Noise Ratio (CNR)**: CNR is similar to SNR but evaluates the contrast between two regions of interest, making it useful for comparing different tissues (e.g., tumor vs. normal tissue). CNR is the difference in mean intensity between two regions divided by the standard deviation of the background.\n",
    "3. **Sharpness (Edge Detection)**: Sharpness can be quantified by measuring the gradient magnitude at edges in the image. Sharper edges usually correspond to better image quality. You can use methods like the Sobel or Laplacian filter to assess image sharpness.\n",
    "4. **Root Mean Square Error (RMSE)**:RMSE compares the difference between the original image and a processed version of the image (e.g., after filtering or compression) to evaluate how much detail has been lost. RMSE is calculated by taking the square root of the mean squared difference between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import sobel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the NIfTI file\n",
    "brain_vol = nib.load('/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/brain1.nii')\n",
    "brain_vol_data = brain_vol.get_fdata()\n",
    "\n",
    "# Define regions (adjust slices as needed)\n",
    "signal_region = (slice(100, 150), slice(100, 150))\n",
    "noise_region = (slice(0, 50), slice(0, 50))\n",
    "region1 = (slice(50, 100), slice(50, 100))  # Example region 1 (e.g., tumor)\n",
    "region2 = (slice(150, 200), slice(150, 200))  # Example region 2 (e.g., healthy tissue)\n",
    "\n",
    "#1. Signal-to-Noise Ratio (SNR)\n",
    "def calculate_snr(image_data, signal_region, noise_region):\n",
    "    signal_mean = np.mean(image_data[signal_region])\n",
    "    noise_std = np.std(image_data[noise_region])\n",
    "    snr = signal_mean / noise_std\n",
    "    return snr\n",
    "\n",
    "snr_value = calculate_snr(brain_vol_data, signal_region, noise_region)\n",
    "print(f\"Signal-to-Noise Ratio (SNR): {snr_value}\")\n",
    "\n",
    "#2. Contrast-to-Noise Ratio (CNR)\n",
    "def calculate_cnr(image_data, region1, region2, noise_region):\n",
    "    region1_mean = np.mean(image_data[region1])\n",
    "    region2_mean = np.mean(image_data[region2])\n",
    "    noise_std = np.std(image_data[noise_region])\n",
    "    cnr = (region1_mean - region2_mean) / noise_std\n",
    "    return cnr\n",
    "\n",
    "cnr_value = calculate_cnr(brain_vol_data, region1, region2, noise_region)\n",
    "print(f\"Contrast-to-Noise Ratio (CNR): {cnr_value}\")\n",
    "\n",
    "#3. Sharpness\n",
    "def calculate_sharpness(image_data):\n",
    "    sobel_x = sobel(image_data, axis=0)\n",
    "    sobel_y = sobel(image_data, axis=1)\n",
    "    edge_magnitude = np.hypot(sobel_x, sobel_y)\n",
    "    return edge_magnitude\n",
    "\n",
    "# Compute sharpness\n",
    "edge_magnitude = calculate_sharpness(brain_vol_data)\n",
    "sharpness_value = np.mean(edge_magnitude)\n",
    "print(f\"Sharpness: {sharpness_value}\")\n",
    "\n",
    "# Optionally display a slice of the edge magnitude\n",
    "plt.imshow(np.mean(edge_magnitude, axis=2), cmap='gray')  # Show a slice\n",
    "plt.title('Edge Magnitude (Sharpness)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 4. Root Mean Square Error (RMSE)\n",
    "# Apply Gaussian filter to create a processed version of the image\n",
    "sigma = 2  # Standard deviation for Gaussian kernel\n",
    "processed_image = gaussian_filter(brain_vol_data, sigma=sigma)\n",
    "\n",
    "def calculate_rmse(original_image, processed_image):\n",
    "    original_flat = original_image.flatten()\n",
    "    processed_flat = processed_image.flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(original_flat, processed_flat))\n",
    "    return rmse\n",
    "\n",
    "# Compute RMSE between the original and filtered images\n",
    "rmse_value = calculate_rmse(brain_vol_data, processed_image)\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_value}\")\n",
    "\n",
    "# Optionally display a slice of the processed image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.mean(processed_image, axis=2), cmap='gray')  # Show a slice\n",
    "plt.title('Processed Image Slice')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import sobel, gaussian_filter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "\n",
    "# Load the DICOM file\n",
    "dicom_file_path = '/home/toshnapanjwani/Documents/Coursework/INFO-H-500/TP_Solutions/DICOM/IM-0004-0096.dcm'\n",
    "dicom_data = pydicom.dcmread(dicom_file_path)\n",
    "dicom_image_data = dicom_data.pixel_array\n",
    "\n",
    "# Define regions (adjust slices as needed)\n",
    "signal_region = (slice(100, 150), slice(100, 150))\n",
    "noise_region = (slice(0, 50), slice(0, 50))\n",
    "region1 = (slice(50, 100), slice(50, 100))  # Example region 1 (e.g., tumor)\n",
    "region2 = (slice(150, 200), slice(150, 200))  # Example region 2 (e.g., healthy tissue)\n",
    "\n",
    "# 1. Signal-to-Noise Ratio (SNR)\n",
    "def calculate_snr(image_data, signal_region, noise_region):\n",
    "    signal_mean = np.mean(image_data[signal_region])\n",
    "    noise_std = np.std(image_data[noise_region])\n",
    "    snr = signal_mean / noise_std\n",
    "    return snr\n",
    "\n",
    "snr_value = calculate_snr(dicom_image_data, signal_region, noise_region)\n",
    "print(f\"Signal-to-Noise Ratio (SNR): {snr_value}\")\n",
    "\n",
    "# 2. Contrast-to-Noise Ratio (CNR)\n",
    "def calculate_cnr(image_data, region1, region2, noise_region):\n",
    "    region1_mean = np.mean(image_data[region1])\n",
    "    region2_mean = np.mean(image_data[region2])\n",
    "    noise_std = np.std(image_data[noise_region])\n",
    "    cnr = (region1_mean - region2_mean) / noise_std\n",
    "    return cnr\n",
    "\n",
    "cnr_value = calculate_cnr(dicom_image_data, region1, region2, noise_region)\n",
    "print(f\"Contrast-to-Noise Ratio (CNR): {cnr_value}\")\n",
    "\n",
    "# 3. Sharpness\n",
    "def calculate_sharpness(image_data):\n",
    "    sobel_x = sobel(image_data, axis=0)\n",
    "    sobel_y = sobel(image_data, axis=1)\n",
    "    edge_magnitude = np.hypot(sobel_x, sobel_y)\n",
    "    return edge_magnitude\n",
    "\n",
    "# Compute sharpness\n",
    "edge_magnitude = calculate_sharpness(dicom_image_data)\n",
    "sharpness_value = np.mean(edge_magnitude)\n",
    "print(f\"Sharpness: {sharpness_value}\")\n",
    "\n",
    "# Display a slice of the edge magnitude\n",
    "if edge_magnitude.ndim == 3:\n",
    "    # Display a slice if edge_magnitude is 3D\n",
    "    plt.imshow(edge_magnitude[:, :, edge_magnitude.shape[2] // 2], cmap='gray')  # Show the middle slice\n",
    "else:\n",
    "    # Display the whole image if edge_magnitude is 2D\n",
    "    plt.imshow(edge_magnitude, cmap='gray')\n",
    "plt.title('Edge Magnitude (Sharpness)')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 4. Root Mean Square Error (RMSE)\n",
    "# Apply Gaussian filter to create a processed version of the image\n",
    "sigma = 2  # Standard deviation for Gaussian kernel\n",
    "processed_image = gaussian_filter(dicom_image_data, sigma=sigma)\n",
    "\n",
    "def calculate_rmse(original_image, processed_image):\n",
    "    original_flat = original_image.flatten()\n",
    "    processed_flat = processed_image.flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(original_flat, processed_flat))\n",
    "    return rmse\n",
    "\n",
    "# Compute RMSE between the original and filtered images\n",
    "rmse_value = calculate_rmse(dicom_image_data, processed_image)\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_value}\")\n",
    "\n",
    "# Optionally display a slice of the processed image\n",
    "plt.imshow(processed_image, cmap='gray')  # Show the processed image\n",
    "plt.title('Processed Image Slice')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d5a64",
   "metadata": {},
   "source": [
    "### Coding Project - **DICOM and NIfTI enhancement**\n",
    "\n",
    "Convert a the.dcm file used in this notebook to a .nii file, and assess the conversion using image quality measurements\n",
    "\n",
    "You have previously worked with basic image processing techniques such as filtering and edge detection on standard image formats like PNG and JPEG. Explore how these same methods can be applied to DICOM and NIfTI images. Identify commonalities and differences in how these techniques affect image quality across different formats. \n",
    "\n",
    "Assess the impact of these image processing steps you have chosen on the image quality by calculating metrics such as Root Mean Square Error (RMSE), SNR, CNR, etc. Compare the image quality metrics and preprocessing effects between DICOM and NIfTI formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556cf9f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
